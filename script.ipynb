{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Star Trail Image Stacker\n",
    "\n",
    "A rudimentary algorithm for merging multiple pictures of star trails into one, while \"erasing\" light clouds that have passed in front of regions of the picture for a short duration. \n",
    "\n",
    "Usually, multiple short-exposure photos taken of the night sky in clear weather can be directly merged into one using tools such as the \"Lighten\" layer blend mode in Adobe Photoshop, which creates a composite of only the brightest pixels at the same location in all the layers. However, if a small light-grey/white cloud moved across the frame, it obscures that entire region in the merged photo, because it may be lighter than the stars/sky behind it. \n",
    "\n",
    "To counteract this, the same Lighten blending can be applied only to selected pixels of a layer that contain a \"star\". Rather than training a neural network to identify stars in an image and create a binary mask of it with them selected, i found it simpler & quicker to just perform edge-detection in the picture. This selects the stars, which appear as lines/dots with clear contrast, but not clouds which have soft edges. The result is then used as a mask to lighten-blend the image in sequence with its previous one.\n",
    "\n",
    "**Note** : This is an interactive notebook with widgets to adjust the parameters of the algorithm. These may not work/render if disabled in the Jupyter lab / another environment.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'gtk4', 'wx', 'qt4', 'qt5', 'qt6', 'qt', 'osx', 'nbagg', 'notebook', 'agg', 'svg', 'pdf', 'ps', 'inline', 'ipympl', 'widget']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob, os\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import IPython.display as disp\n",
    "\n",
    "# list available backends\n",
    "# 'widget' backend allows interactive plots within the notebook\n",
    "# Matplotlib is convenient for zooming into the image and viewing pixel coordinates/values\n",
    "%matplotlib -l      \n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Select Images\n",
    "\n",
    "- Specify the paths to input images as a list in `SOURCE_PATH`. If it is a serially numbered image sequence, wildcards such as `*`, `[]`, etc can be used with `glob` to generate the list automatically.\n",
    "- `BASE_PATH` contains the path of a single image which will form the bottom-most layer of the image stack. All the other source images are blended together above this, and only their edge-regions will appear above it, while the rest of the background will be the same as that of this image.\n",
    "\n",
    "The file upload widget itself can't be used to generate the list, it's just to browse the filesystem from here. Copy the address string of the files into the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory : /Users/gautamd/Home/github/startrail-merger\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2caefb78df042fc8ca62bd4ad2a18cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='image/*', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SOURCE_PATH = glob.glob(\"./data/*.jpg\")\n",
    "BASE_PATH   = \"./data/4J7A6511.jpg\"\n",
    "\n",
    "print(\"Current Working Directory :\", os.getcwd())\n",
    "widgets.FileUpload(accept='image/*', multiple=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_PATH.sort()\n",
    "\n",
    "if not SOURCE_PATH:\n",
    "    raise FileNotFoundError(\"Please set a valid image sequence path for SOURCE_PATH\")\n",
    "if not os.path.isfile(BASE_PATH):\n",
    "    raise FileNotFoundError(\"Please set a valid image path for BASE_PATH\")\n",
    "\n",
    "\n",
    "_abs_source = list(map(os.path.abspath, SOURCE_PATH))\n",
    "if os.path.abspath(BASE_PATH) in _abs_source:\n",
    "    SOURCE_PATH.pop(_abs_source.index(os.path.abspath(BASE_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayimg(img, title=None, close=None):\n",
    "    \"\"\"Use matplotlib to display an image\"\"\"\n",
    "    \n",
    "    fax = fig, ax = plt.subplots()\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if title :\n",
    "        ax.set_title(title)\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0.1, right=0.9)\n",
    "    if isinstance(close, plt.Figure) :\n",
    "        plt.close(close)\n",
    "    return fax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Slice\n",
    "\n",
    "To reduce the time taken to re-process the entire image everytime any parameters are tweaked, you can choose to just process a sub-section of the image.\n",
    "Specify\n",
    "\n",
    "```SLICE = (x1, y1, x2, y2)``` \n",
    "\n",
    "to identify the top-left (x1, y1) and bottom-right (x2, y2) of the rectangular region to process.\n",
    "- Use `SLICE = (0, 0, *baseImg.shape[:2])` to select the entire Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1aea31d94e453b9b932f884159857f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 1 Axes>,\n",
       " <AxesSubplot:title={'center':'Base Image'}>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseImg = cv2.imread(BASE_PATH)\n",
    "\n",
    "SLICE = (0, 0, *baseImg.shape[:2])\n",
    "# SLICE = (2000, 500, 3500, 1500)\n",
    "\n",
    "displayimg(baseImg[SLICE[1]:SLICE[2], SLICE[0]:SLICE[3]], \"Base Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_kernel = np.array([[-1, -1, -1],\n",
    "                           [-1, 8, -1],\n",
    "                           [-1, -1, -1]])\n",
    "\n",
    "dil_kernel = np.ones((3, 3), np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Blending\n",
    "\n",
    "The following cell contains the code to blend the images. There are 4 adjustable parameters for creating the masks :\n",
    "- `edge_tol` : A scalar that will be multiplied with the convolution kernel for outline selection.\n",
    "- `blur_size` : Kernel size for smoothing the image after edge detection, reduces noise.\n",
    "- `dil_iter` : Number of dilation iterations to the smoothed edge mask, to marginally increase width of the selected area.\n",
    "- `thresh` : Threshold grayscale value for creating a binary mask from the image (how much to finally select).\n",
    "\n",
    "Click on the **Run Interact** button to process the images.\n",
    "\n",
    "Checking '_Save_' will also save each image to the location `./processed/{filename}` where `.` is the current directory. If such an image already exists, it will fail unless '_Overwrite_' is also checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Selective Blending"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc51439810b40e98e95848b85a6cc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=7, description='edge_tol', max=14, min=1), IntSlider(value=3, descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgStack = baseImg[SLICE[1]:SLICE[2], SLICE[0]:SLICE[3]]\n",
    "imgView = None\n",
    "\n",
    "disp.display(disp.Markdown(\"### Selective Blending\"))\n",
    "\n",
    "@widgets.interact_manual(edge_tol=(1,14), blur_size=(3,13,2), dil_iter=(1,5), thresh=(10,250,10), save=False, overwrite=False)\n",
    "\n",
    "def blend(edge_tol=7, blur_size=3, dil_iter=1, thresh=120, save=False, overwrite=False):\n",
    "\n",
    "    global imgStack, imgView\n",
    "\n",
    "    for ipath in SOURCE_PATH:\n",
    "        img = cv2.imread(ipath)[SLICE[1]:SLICE[2], SLICE[0]:SLICE[3]]\n",
    "\n",
    "        i2outl = cv2.filter2D(img, -1, outline_kernel * edge_tol/7)\n",
    "        i2olgr = cv2.cvtColor(i2outl, cv2.COLOR_BGR2GRAY)\n",
    "        i2noisrm = cv2.medianBlur(i2olgr, blur_size)\n",
    "        i2med1 = cv2.dilate(i2noisrm, dil_kernel, iterations=dil_iter)\n",
    "        i2mask = cv2.threshold(i2med1, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        masked2 = cv2.bitwise_and(np.stack([i2mask]*3, axis=2), img)\n",
    "        imgStack = cv2.max(masked2, imgStack)\n",
    "        \n",
    "        if save:\n",
    "            if not os.path.isdir('./processed'):\n",
    "                os.mkdir('./processed')\n",
    "            p = './processed/'+os.path.split(ipath)[1]\n",
    "            if os.path.isfile(p):\n",
    "                if overwrite : os.remove(p)\n",
    "                else : raise FileExistsError(f\"{os.path.abspath(p)} cannot be replaced. You must enable the 'overwrite' option\")\n",
    "            cv2.imwrite(p, imgStack)\n",
    "            print(\"saving\", os.getcwd()+'/processed/'+os.path.split(ipath)[1])\n",
    "\n",
    "    imgView = displayimg(imgStack, close=imgView)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "> The following cell also blends the images, but without computing any mask (directly lighten the whole image, hence there are no parameters).\n",
    "> This can be used as a 'control' to compare with the previous result.\n",
    "\n",
    "Images are saved at `./processed/d_{filename}` if enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Direct Blending"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e5c123ad6f4fef9a24df85e1d3a984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Checkbox(value=False, description='save'), Checkbox(value=False, description='overwrite'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgStackDt = baseImg[SLICE[1]:SLICE[2], SLICE[0]:SLICE[3]]\n",
    "imgViewDt  = None\n",
    "\n",
    "disp.display(disp.Markdown(\"### Direct Blending\"))\n",
    "\n",
    "@widgets.interact_manual(save=False, overwrite=False)\n",
    "\n",
    "def blend_direct(save=False, overwrite=False):\n",
    "\n",
    "    global imgStackDt, imgViewDt\n",
    "\n",
    "    for ipath in SOURCE_PATH:\n",
    "        img = cv2.imread(ipath)[SLICE[1]:SLICE[2], SLICE[0]:SLICE[3]]\n",
    "        imgStackDt = cv2.max(img, imgStackDt)\n",
    "        \n",
    "        if save:\n",
    "            if not os.path.isdir('./processed'):\n",
    "                os.mkdir('./processed')\n",
    "            p = './processed/d_'+os.path.split(ipath)[1]\n",
    "            if os.path.isfile(p):\n",
    "                if overwrite : os.remove(p)\n",
    "                else : raise FileExistsError(f\"{os.path.abspath(p)} cannot be replaced. You must enable the 'overwrite' option\")\n",
    "            cv2.imwrite(p, imgStackDt)\n",
    "            print(\"saving\", os.getcwd()+'/processed/'+os.path.split(ipath)[1])\n",
    "\n",
    "    imgView = displayimg(imgStackDt, close=imgViewDt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
